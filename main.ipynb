{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T15:21:08.464731Z",
     "start_time": "2024-10-10T15:21:08.459992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "import beacon\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import ParabolaGen\n",
    "import NoiseGen"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T15:21:11.586685Z",
     "start_time": "2024-10-10T15:21:09.362050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_dim = 92\n",
    "y_dim = 120\n",
    "time_dimension = 1000\n",
    "num_of_files = 1\n",
    "origin = None    #Set to none to have random origins, or input coordinates (x,y, ToF)\n",
    "\n",
    "train_data = ParabolaGen.generate_parabola(x_dim, y_dim, time_dimension, 128, origin).unsqueeze(1)\n",
    "test_data = ParabolaGen.generate_parabola(x_dim, y_dim, time_dimension, 32, origin).unsqueeze(1)\n",
    "\n",
    "train_data_noisy = torch.clamp((NoiseGen.generate_gaussian_noise(128, 120, 92, mean=0, std=0.1) + NoiseGen.generate_binary_noise(128, 120, 92, magnitude=1, p=0.3)).unsqueeze(1) + train_data, 0, 1)\n",
    "test_data_noisy = torch.clamp((NoiseGen.generate_gaussian_noise(32, 120, 92, mean=0, std=0.1) + NoiseGen.generate_binary_noise(32, 120, 92, magnitude=1, p=0.3)).unsqueeze(1) + test_data, 0, 1)"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T15:21:14.822253Z",
     "start_time": "2024-10-10T15:21:14.807694Z"
    }
   },
   "cell_type": "code",
   "source": "train_data.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 120, 92])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(train_data[0][0])\n",
    "ax[1].imshow(train_data_noisy[0][0])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class LinearAutoencoder(beacon.Module):\n",
    "    def __init__(self, input_features):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_features, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(128, 16),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(16, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.2),\n",
    "            torch.nn.Linear(128, input_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T15:15:17.929948Z",
     "start_time": "2024-10-10T15:15:17.916241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ConvolutionAutoencoder(beacon.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 64, 3, stride=1),  # Output: (16, 60, 45)\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64, 16, 3, stride=1), # Output: (32, 30, 23)\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(16, 8, 3, stride=1), # Output: (64, 15, 12)\n",
    "            torch.nn.BatchNorm2d(8),\n",
    "            torch.nn.ReLU(),\n",
    "            # torch.nn.Flatten(1),\n",
    "            # torch.nn.Linear(64*114*84, 128),\n",
    "            # torch.nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            # torch.nn.Linear(128, 64*114*84),\n",
    "            # torch.nn.ReLU(),\n",
    "            # torch.nn.Unflatten(1, (64, 114, 84)),\n",
    "            torch.nn.ConvTranspose2d(8, 16, 3, stride=1), # Output: (32, 30, 23)\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(16, 64, 3, stride=1), # Output: (16, 60, 45)\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.ConvTranspose2d(64, 1, 3, stride=1), # Output: (1, 120, 90)\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T15:15:57.091802Z",
     "start_time": "2024-10-10T15:15:56.916528Z"
    }
   },
   "cell_type": "code",
   "source": "summary(ConvolutionAutoencoder(), input_size=(1, 1, 120, 92))",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Conv2d: 2]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[1;32m~\\miniconda3\\envs\\ResearchProject\\Lib\\site-packages\\torchinfo\\torchinfo.py:295\u001B[0m, in \u001B[0;36mforward_pass\u001B[1;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001B[0m\n\u001B[0;32m    294\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[1;32m--> 295\u001B[0m     _ \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;241m*\u001B[39mx, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    296\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mdict\u001B[39m):\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ResearchProject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ResearchProject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1603\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1601\u001B[0m     args \u001B[38;5;241m=\u001B[39m bw_hook\u001B[38;5;241m.\u001B[39msetup_input_hook(args)\n\u001B[1;32m-> 1603\u001B[0m result \u001B[38;5;241m=\u001B[39m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1604\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks:\n",
      "Cell \u001B[1;32mIn[24], line 35\u001B[0m, in \u001B[0;36mConvolutionAutoencoder.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 35\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(x)\n\u001B[0;32m     36\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(x)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ResearchProject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ResearchProject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1603\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1601\u001B[0m     args \u001B[38;5;241m=\u001B[39m bw_hook\u001B[38;5;241m.\u001B[39msetup_input_hook(args)\n\u001B[1;32m-> 1603\u001B[0m result \u001B[38;5;241m=\u001B[39m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1604\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ResearchProject\\Lib\\site-packages\\torch\\nn\\modules\\container.py:219\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 219\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m    220\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ResearchProject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1552\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1553\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ResearchProject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1603\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1601\u001B[0m     args \u001B[38;5;241m=\u001B[39m bw_hook\u001B[38;5;241m.\u001B[39msetup_input_hook(args)\n\u001B[1;32m-> 1603\u001B[0m result \u001B[38;5;241m=\u001B[39m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1604\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ResearchProject\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:143\u001B[0m, in \u001B[0;36m_BatchNorm.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 143\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_input_dim(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;66;03m# exponential_average_factor is set to self.momentum\u001B[39;00m\n\u001B[0;32m    146\u001B[0m     \u001B[38;5;66;03m# (when it is available) only so that it gets updated\u001B[39;00m\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;66;03m# in ONNX graph when this node is exported to ONNX.\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ResearchProject\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:426\u001B[0m, in \u001B[0;36mBatchNorm2d._check_input_dim\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    425\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m4\u001B[39m:\n\u001B[1;32m--> 426\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexpected 4D input (got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28minput\u001B[39m\u001B[38;5;241m.\u001B[39mdim()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mD input)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: expected 4D input (got 3D input)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m summary(ConvolutionAutoencoder(), input_size\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m120\u001B[39m, \u001B[38;5;241m92\u001B[39m))\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ResearchProject\\Lib\\site-packages\\torchinfo\\torchinfo.py:223\u001B[0m, in \u001B[0;36msummary\u001B[1;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001B[0m\n\u001B[0;32m    216\u001B[0m validate_user_params(\n\u001B[0;32m    217\u001B[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001B[0;32m    218\u001B[0m )\n\u001B[0;32m    220\u001B[0m x, correct_input_size \u001B[38;5;241m=\u001B[39m process_input(\n\u001B[0;32m    221\u001B[0m     input_data, input_size, batch_dim, device, dtypes\n\u001B[0;32m    222\u001B[0m )\n\u001B[1;32m--> 223\u001B[0m summary_list \u001B[38;5;241m=\u001B[39m forward_pass(\n\u001B[0;32m    224\u001B[0m     model, x, batch_dim, cache_forward_pass, device, model_mode, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    225\u001B[0m )\n\u001B[0;32m    226\u001B[0m formatting \u001B[38;5;241m=\u001B[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001B[0;32m    227\u001B[0m results \u001B[38;5;241m=\u001B[39m ModelStatistics(\n\u001B[0;32m    228\u001B[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001B[0;32m    229\u001B[0m )\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\ResearchProject\\Lib\\site-packages\\torchinfo\\torchinfo.py:304\u001B[0m, in \u001B[0;36mforward_pass\u001B[1;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001B[0m\n\u001B[0;32m    302\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    303\u001B[0m     executed_layers \u001B[38;5;241m=\u001B[39m [layer \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m summary_list \u001B[38;5;28;01mif\u001B[39;00m layer\u001B[38;5;241m.\u001B[39mexecuted]\n\u001B[1;32m--> 304\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    305\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    306\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecuted layers up to: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexecuted_layers\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    307\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    309\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m hooks:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Conv2d: 2]"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "autoencoder = ConvolutionAutoencoder().to(\"mps\")\n",
    "loss_function = torch.nn.MSELoss()\n",
    "optimiser = torch.optim.Adam(autoencoder.parameters(), lr=0.003)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for epoch in tqdm(range(100)):\n",
    "    optimiser.zero_grad()\n",
    "    outputs = autoencoder(train_data_noisy.to(\"mps\"))\n",
    "    loss = loss_function(outputs, train_data.to(\"mps\"))\n",
    "    loss.backward()\n",
    "    optimiser.step()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "autoencoder.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = autoencoder.to(\"cpu\")(test_data_noisy[0].unsqueeze(0).to(\"cpu\"))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "ax[0].imshow(test_data_noisy[0][0].to(\"cpu\"))\n",
    "ax[1].imshow(test_data[0][0].to(\"cpu\"))\n",
    "ax[2].imshow(pred[0][0])\n",
    "\n",
    "ax[0].set_title(\"Noisy Input\")\n",
    "ax[1].set_title(\"Original Image\")\n",
    "ax[2].set_title(\"Reconstructed Image\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
